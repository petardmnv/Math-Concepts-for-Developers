{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Класификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какво е машинно обучение\n",
    "\n",
    "Машинното обучение се занимава със създаването на алгоритми, които се учат от данни, така че програмите и системите да могат да изпълняват задачи без изричен набор от програмирани инструкции - например технологията за разпознаване на изображения често разчита на алгоритми за машинно обучение, които анализират огромен брой снимки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контролирано и неконтролирано обучение\n",
    "Има три различни стила на обучение в алгоритмите за машинно обучение:\n",
    "1. Контролирано\n",
    "2. Неконтролирано\n",
    "3. Полу-контролирано обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целта на **Контролираното обучение** е да приспособим модел, който свързва отговора(зависими променливи) с предикторите(независими променливи), с цел точно предсказване на отговора за бъдещи наблюдения или по-добро разбиране на връзката между отговора и предикторите. Много класически статистически методи за обучение като линейна регресия и логистична регресия, също така и по-модерни подходи като GAM, ускоряване и поддържане на машини за регресия на вектори, работят в контролираната област на обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Неконтролираното обучение** е малко по-предизвикателната задача, при която за всяко наблюдение i = 1, ..., n, ние наблюдаваме вектор на измервания xi, но няма свързан отговор yi. При неконтролираното обучение не може  да се побере модел на линейна регресия, тъй като няма променлива за отговор, която да се предскаже. В тази обстановка в някакъв смисъл работим на сляпо; ситуацията се нарича без надзор, тъй като ни липсва променлива за отговор, която може да контролира нашия анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регресия\n",
    "\n",
    "#### 1. Дефиниция:\n",
    "    Регресията е статистически метод, използван във финансите, инвестициите и други дисциплини, който се опитва да определи силата и характера на връзката между една зависима променлива (обикновено обозначена с Y) и поредица от други променливи (известни като независими променливи X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Видове регресии:\n",
    "    1. Ordinary Least Squares Regression (OLSR)\n",
    "    2. Linear Regression\n",
    "    3. Logistic Regression\n",
    "    4. Stepwise Regression\n",
    "    5. Multivariate Adaptive Regression Splines (MARS)\n",
    "    6. Locally Estimated Scatterplot Smoothing (LOESS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класифицация\n",
    "#### 1. Дефиниция:\n",
    "    Техника, при която категоризираме данните в даден брой класове. Основната цел на проблема с класификацията е да се идентифицира категорията / класът, към който ще попадат нови данни.\n",
    "\n",
    "\n",
    "#### 2. Кога се използва: \n",
    "\n",
    "    Променливите за отговор могат да се характеризират като количествени или качествени (също известни като категориини). Количествените променливи приемат числови стойности (доходи, височина на хората, цена на стока и др.). За разлика от количествените, качествените променливи приемат стойности в един от K различни класове или категории. Примерите за качествени променливи включват пола на човек (мъж или жена), марката на закупения продукт (марка A, B или C) и др. Когато имаме проблеми от количествен тип, считаме че те са свързани с проблеми с регресията, докато тези, включващи качествен отговор, често се отнасят за проблеми с класификацията. В много ситуации променливата за отговор е качествена. Например полът на човек е качествен, като приема стойности мъж или жена(дано да не ме съдят \"европейците\" ;)). В случай, че имаме проблем свързан със машинно обучение, в който променливата за отговор е качествена ще използваме класификация, за да категоризираме данните, които имаме и да можем да определим към кой клас ще попаднат нови данни, ако има такива.\n",
    "    \n",
    "    Ще демонстрирам какво означава отговорът да е от тип количествен или качествен като използвам измислен от мен мини дата сет\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_boys_heights_in_uk = [0.48, 0.63, 0.71, 0.77, 0.86, 0Note.92, 1.0, 1.08, 1.14, 1.21, 1.27, 1.34, 1.44, 1.52, 1.65, 1.74, 1.81, 1.84, 1.85, 1.85]\n",
    "avg_boys_heights_in_bg = [0.45, 0.61, 0.69, 0.73, 0.80, 0.88, 0.95, 1.03, 1.10, 1.17, 1.24, 1.31, 1.39, 1.47, 1.58, 1.69, 1.74, 1.76, 1.76, 1.76]\n",
    "avg_boys_heights_in_nk = [0.40, 0.49, 0.56, 0.64, 0.72, 0.81, 0.89, 0.97, 1.04, 1.1, 1.17, 1.23, 1.31, 1.40, 1.51, 1.62, 1.69, 1.7, 1.71, 1.71]\n",
    "avg_boys_heights_in_us = [0.50, 0.61, 0.69, 0.75, 0.84, 0.95, 1.02, 1.11, 1.18, 1.26, 1.35, 1.43, 1.54, 1.66, 1.75, 1.82, 1.85, 1.87, 1.87, 1.87]\n",
    "plt.scatter([i for i in range(1, len(avg_boys_heights_in_uk) + 1)], avg_boys_heights_in_uk, color='r')\n",
    "plt.scatter([i for i in range(1, len(avg_boys_heights_in_bg) + 1)], avg_boys_heights_in_bg, color='r')\n",
    "plt.scatter([i for i in range(1, len(avg_boys_heights_in_nk) + 1)], avg_boys_heights_in_nk, color='r')\n",
    "plt.scatter([i for i in range(1, len(avg_boys_heights_in_us) + 1)], avg_boys_heights_in_us, color='r')\n",
    "\n",
    "plt.title(\"Quantitative parameters\")\n",
    "plt.xticks(range(1, 21, 2))\n",
    "#plt.yticks()\n",
    "plt.ylabel(\"Boys Height in [m]\")\n",
    "plt.xlabel(\"Boys age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В този случай пазглеждаме **измислени** от мен данни за височината на момчета от 1 до 20 години в различни страни. В този случай търсената стойност (отговора) е количествен, а именно височината в метри. Следователно ако си пиша с момче на 14 години и не съм го виждал наживо, то от данните, с които разполагам мога да предположа, че височината му ще варира от 1.35 до 1.7. За да направя това предположение, не ми е нужна класификация, а регресия или по точно регресионни алгоритми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "passed_exam_hours_studied = np.array((np.random.rand(1, 25) + 0.9) * 4.845)\n",
    "passed_exam_hours_slept = np.array((np.random.rand(1, 25) + 1.3) * 4.45)\n",
    "failed_exam_hours_studied = np.array((np.random.rand(1, 25) + 0.2) * 4.845)\n",
    "failed_exam_hours_slept = np.array((np.random.rand(1, 25) + 0.4) * 4.45)\n",
    "plt.scatter(passed_exam_hours_slept, passed_exam_hours_studied, color = 'r', label='Passed') \n",
    "plt.scatter(failed_exam_hours_slept, failed_exam_hours_studied, color = 'b', label='Failed') \n",
    "\n",
    "plt.ylabel(\"Hours studied\")\n",
    "plt.xlabel(\"Hours slept\")\n",
    "plt.legend()\n",
    "plt.title(\"Qualitative parameters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В този случай пазглеждаме **измислени** от мен данни за ученици като правата по OX показва колко часа са спали учениците преди контролно, а правата по OY показва колко часа са учили за контролното. Точките в червено са данните на учениците, които са минали контролното, а тези в синьо са данните на учениците, който са се провалили на контролното. Да кажем, че след една година, следващият випуск прави същото контролно. Ако знаем колко време са отделили новите ученици, то на базата на старите данни можем да предположим кои ще минат изпита и кои не. Следователно, ако Иванчо не е учил за теста и е спал нормално, то можем да кажем, че той ще бъде скъсан, докато Иванка, която е учила четири часа за изпита и е спала около седем часа ще вземе изпита. За да направя това предположение ми е нужна класификация, тъй като предположението (отговорът) ми е качествен (минал/скъсан). \n",
    "\n",
    "По какъв начин може да се формира класификацията, обаче? Втора точка отговаря на въпроса. Има много методи за класификация, ето някои от тях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Типове класификационни методи:\n",
    "    1. Logistic Regression\n",
    "    2. Naïve Bayes\n",
    "    3. Stochastic Gradient Descent\n",
    "    4. K-Nearest Neighbours\n",
    "    5. Decision Tree\n",
    "    6. Random Forest\n",
    "    7. Support Vector Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Логистична регресия(формули и реализация):\n",
    "Първо нека да започнем с определението за логистична регресия - Логистичната регресия е алгоритъм, който се използва за изчисляване на вероятността от възникване на няколко събития(обикновенно две(binary class...), но може и повече от две(multy-class)) и за справяне с въпросите на класификацията. Например прогнозиране дали входящият имейл е спам или не, или прогнозиране дали транзакцията с кредитна карта е измамна или не. В медицински контекст може да се използва логистична регресия, за да се предскаже дали туморът е доброкачествен или злокачествен.\n",
    "​\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сигмоидна функция(Sigmoid function)**\n",
    "\n",
    "След като прочетем определението може да предположим, че по зададени променливи $X$ трябва да определим дали обекта принадлежи на клас 1 или клас 2. Следователно ще ни трябва някаква функция която да осъществява връзката междъ $X$ и $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да кажем, че това е функцията( $ z = wx + b $ ), която връща стойности в интервала  \n",
    "    $z \\in [-\\infty, +\\infty]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемът е, че не искаме да имаме стойности извън интервала  $ [0, 1] $, защото имаме два класа - 0 за клас1 и 1 за клас 2. За да решим този проблем, на помощ идва сигмоидната функция, която връща стойности в интервала $ [0, 1] $ независимо какво ще и подадем като аргумент.\n",
    "\n",
    "Следователно можем да подадем $ z $ като такъв аргумент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ S(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "където:\n",
    "1. $ z = xw + b $\n",
    "\n",
    "2. w - тежест на независимите променливи $X$\n",
    "\n",
    "3. b - наклон на функцията\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От тук нататък аз ще използвам формулата: $$ z = \\theta^T \\mathbf{x} $$\n",
    "\n",
    "където\n",
    "\n",
    "1. $ \\theta $ е матрица от тежести w\n",
    "\n",
    "2. $ \\mathbf{x} $ е матрица от независимите променливи на уравнението\n",
    "3. Размерът на двете матрици е едни и същ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тъй като ги умножавам си позволявам да транспонирам матрицата от тежести.\n",
    "\n",
    "##### Обобщение до тук:\n",
    "От определението за регресия, накратко, можем да разберем, че ни трябва да намерим връзката между $ x $ и $y$. Следователно в нашия случай ще се опитаме да намерим възможно най-близкото решение на уравнението:\n",
    "$$ y = \\frac{1}{1 + e^{\\theta^T \\mathbf{x}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоест ако $y_i = 1$ (означаваме клас1 с $y = 0$ и клас2 с $y = 1$), трябва да получим възможно най-близкия резултат до 1, когато подадем на уравнението $ y_i = \\frac{1}{1 + e^{\\theta^T \\mathbf{x_i}}} $ съответните $ \\theta^T \\mathbf{x_i} $ за $ y_i $.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заключение\n",
    "Трябва да намерим параметрите - $ \\theta $ (стойностите на тежестите на всеки един от елементите на $ \\mathbf{x} $) на модела, така че вероятността да се получи резултат, такъв какъвто имаме като информация от датасета, да е най-голяма. В този случай $y\\space \\epsilon \\space[0, 1]$ като $ y = \\frac{1}{1 + e^{\\theta^T \\mathbf{x}}} $.\n",
    "\n",
    "\n",
    "Този процес ще наречем трениране на модела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как да намерим стойностите на $ \\theta $\n",
    "Проблем: Как да намеря параметрите - каква формула да ползвам.\n",
    "Решение: MLE - Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Какво представлява MLE - Maximum Likelihood Estimation\n",
    "Досега не споменах какво точно е $ y $. Да кажем, че имаме N на брой данни от дейтабейса. За всяка една променлива трябва да кажем към кой клас се отнася. Следователно си създаваме матрица със 0 и 1-ци, които съответно отговарят на това дали променливата i е от първия клас(0) или от втория клас(1). Пример: Ако отново разгледаме данните, които си измислих - Данни за ученици като правата по OX показва колко часа са спали учениците преди контролно, а правата по OY показва колко часа са учили за контролното. То трябва да направя матрица със размер - броя на учениците, в която да пише за всеки ученик дали е минал теста или е скъсан т.е. на всеки ред ще има 0 или 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В заключението по-горе споменах за вероятност. Време е да запишем тази вероятност като формула:\n",
    "$$ P(Y\\mid X;\\theta) $$\n",
    "където\n",
    "\n",
    "1. Y - Матрицата от класифицирани променливи\n",
    "\n",
    "2. X - Матрицата с променливите\n",
    "\n",
    "3. $ \\theta $ - Тежестите на променливите\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE - Maximum Likelihood Estimation представлява максималната вероятност, при намиране на параметрите $ \\theta $ и  извършване на сигмоидната функция върху зададения модел, да се получат резултати, такива каквито са и резултатите в Y. \n",
    "\n",
    "Формула:\n",
    "\n",
    "$$ \\hat{\\theta}^{MLE} = arg\\space max\\space \\prod^n_{i = 0}P(y_i\\mid \\mathbf{x_i};\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Търсим maksimalnoto proizwedenie на всяка вероятност, за която ще се намери $y_i$ по подадени $ \\mathbf{x_i} $\n",
    "\n",
    "Вероятността $ P(y_i\\mid \\mathbf{x_i};\\theta) $ можем да разгледаме като функцията - $ f(\\theta_0 + \\theta_1 x_{i_1} + \\theta_2 x_{i_2} + \\cdots + \\theta_n x_{i_n})$ като стигаме до $ x_{i_n}$ взависимост от това, колко променливи имаме. Накратко функцията може да се запише като $ f(\\theta^T \\mathbf{x_i}) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблем: Не искаме $ f(\\theta^T \\mathbf{x_i})\\space \\epsilon \\space[-\\infty, +\\infty]$. Трябва ни трансформация на  стойностите от $\\space \\epsilon \\space[-\\infty, +\\infty]$ в стойностите $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение: Използваме сигмоидната функция. $ S(z):\\space[-\\infty, +\\infty] \\rightarrow [0, 1]$ където $ z = f(\\theta^T \\mathbf{x_i}) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слведователно  $ P(y_i\\mid \\mathbf{x_i};\\theta) = S(\\theta^T \\mathbf{x_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека разделим MLE на класове т.е.:\n",
    "\n",
    "$$ \\hat{\\theta}^{MLE} = arg\\space max\\space \\prod^n_{i = 0}P(y_i\\mid \\mathbf{x_i};\\theta) = max\\space \\prod^n_{i = 0}P(y_i = 1\\mid \\mathbf{x_i};\\theta) \\prod^n_{i = 0}P(y_i = 0\\mid \\mathbf{x_i};\\theta)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\prod^n_{i = 0}P(y_i = 0\\mid \\mathbf{x_i};\\theta) $$ е произведението на вероятностите на групата за обучение, която принадлежи към клас1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\prod^n_{i = 0}P(y_i = 1\\mid \\mathbf{x_i};\\theta) $$ е произведението на вероятностите на групата за обучение, която принадлежи към клас2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От Вероятност знаем, че  $ \\overline p(x) = 1 - p(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следователно $$ \\prod^n_{i = 0}P(y_i = 0\\mid \\mathbf{x_i};\\theta) = \\prod^n_{i = 0} 1- P(y_i = 1\\mid \\mathbf{x_i};\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И знаем, че:\n",
    "$$  P(y_i = 1\\mid \\mathbf{x_i};\\theta) = S(\\theta^T \\mathbf{x_i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заместваме в MLE:\n",
    "$$ L (\\theta) = \\hat{\\theta}^{MLE}= max\\space \\prod^n_{i = 0}S(\\theta^T \\mathbf{x_i}) \\prod^n_{i = 0}(\n",
    "1 - S(\\theta^T \\mathbf{x_i}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемът тук е, че при вероятността при единия винаги ще е около 0, защото един обект може да бъде само в един от класовете. Следователно можем да изведем формулата така:\n",
    "\n",
    "$$ L(\\theta) = \\hat{\\theta}^{MLE}= max\\space \\prod^n_{i = 0}S(\\theta^T \\mathbf{x_i})^{y_i} * (\n",
    "1 - S(\\theta^T \\mathbf{x_i}))^{(1 - y_i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Така, ако $ y_i = 1 $ изразът $ (1 - S(\\theta^T \\mathbf{x_i}))^{(1 - y_i)}$ става 1 т.е. не променя нищо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И по същата логика, ако $ y_i = 0 $ изразът $ y_i = 0 $ става 1 т.е. не променя нищо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо умножение ще използваме събиране, защото е по бърза операция, но за тази цел ще се наложи да трансформираме израза малко:\n",
    "$$ l(\\theta) = \\space \\log(\\prod^n_{i = 0} S(\\theta^T \\mathbf{x_i})^{y_i} + (1 - S(\\theta^T \\mathbf{x_i}))^{(1 - y_i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тъй като логаритмите имат свойството $ \\log a^b = b\\log a $. И още едно свойство  $ \\log a+ \\log b = \\log ab $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаваме израза:\n",
    "$$ l(\\theta) = \\space \\sum^n_{i = 0}\\log( S(\\theta^T \\mathbf{x_i})^{y_i}) + \\log(1 - S(\\theta^T \\mathbf{x_i}))^{(1 - y_i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ l(\\theta) =max \\space \\sum^n_{i = 0}y_i\\log( S(\\theta^T \\mathbf{x_i})) + (1 - y_i)\\log(1 - S(\\theta^T \\mathbf{x_i})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отново ако $ y_i = 0 $ изразът $y_i\\log( S(\\theta^T \\mathbf{x_i}))$ се унищожава. Същото важи и за $ y_i = 1 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функцията, която изведохме се нарича MLL - Maximum Log Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тъй като ще използваме Gradient Descent ще ми трябва минимум, а не максимум. Можем да обърнем MLL в NLL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Като $NLL(\\theta) = -l(\\theta)$:\n",
    "$$ NLL(\\theta) = min \\space \\sum^n_{i = 0}y_i\\log( S(\\theta^T \\mathbf{x_i})) + (1 - y_i)\\log(1 - S(\\theta^T \\mathbf{x_i})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За жалост не можем да определим движението на тази функция, затова ще разчитаме на оптимизиращ алгоритъм - Gradient Descent, който да намери локален минимум на функцията NLL. В локалния минимум загубите на NLL ще са най-малки т.е. прецизността на функцията ще е най-голяма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "Целта на оптимизиращия алгоритъм е да се променят стойностите на $ \\theta $, че грешката, която NLL ще \"остави\" селд себе си да бъде възможно най-малка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Как да намерим стойностите на $\\theta$\n",
    "Първо ще запишем случайни числа в $\\theta$. Използвайки Gradient Descent числата ще се променят, така че загубите на NLL ще станат минимални."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритъмът ще изглежда по този начин:\n",
    "\n",
    "                                                For m in range(M):\n",
    "$$ \\theta = \\theta + \\alpha\\frac{\\delta NLL}{\\delta \\theta^T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "като $\\alpha$ e скорост на обучение. Обикновенно $\\alpha = 0.01 $ или $\\alpha = 0.05 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще ни трябва да намерим производната на сигмоидната функция $ S(z) = \\frac{1}{1 + e^{-z}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{d(S(z))}{dx} = \\frac{d(\\frac{1}{1 + e^{-z}})}{dx} = \\frac{d(1 + e^{-z})^{-1}}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще напиша формули, които ще ни помогнат малко по-надолу в обясненията.\n",
    "\n",
    "Полимиалното правило:\n",
    "$$ \\frac{d(f(z)^{a})}{dx} = a f(z)^{a - 1}\\frac{d(f(z))}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Експонентното правило:\n",
    "$$ \\frac{dе^{z}}{dx} = e^z $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логаритмичното правило:\n",
    "$$ \\frac{d\\log(z)}{dx} = \\frac{1}{z} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain Rule(по-добре да не го превеждам):\n",
    "\n",
    "$$ \\frac{\\delta A}{\\delta x} = \\frac{\\delta A}{\\delta y}* \\frac{\\delta y}{\\delta x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да се върнем на производната на сигмоидната функция $ S(z) = \\frac{1}{1 + e^{-z}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{d(1 + e^{-z})^{-1}}{dx} = (-1)(1 + e^{-z})^{-2}* \\frac{d(1 + e^{-z})}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (-1)(1 + e^{-z})^{-2}* \\frac{d(1 + e^{-z})}{dx} = (-1)(1 + e^{-z})^{-2}(-e^{-z}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (-1)(1 + e^{-z})^{-2}(-e^{-z}) = \\frac{e^{-z}}{(1 + e^{-z})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{e^{-z}}{(1 + e^{-z})^2} = \\frac{-1 + 1 + e^{-z}}{1 + e^{-z}} * \\frac{1}{1 + e^{-z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{-1 + 1 + e^{-z}}{1 + e^{-z}} * \\frac{1}{1 + e^{-z}} \\Leftrightarrow S(z)(1 - S(z)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Така изведохме формулата за първата произвопдна на сигмоидната функция:\n",
    "\n",
    "$$ \\frac{d(S(z))}{dx} = S(z)(1 - S(z)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нека разапишем израза $ \\frac{\\delta NLL}{\\delta \\theta^T} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}y_i * \\frac {\\log( S(\\theta^T \\mathbf{x_i}))}{\\delta( S(\\theta^T \\mathbf{x_i}))}* \\frac{\\delta( S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T} + (1 - y_i) * \\frac{\\log(1 - S(\\theta^T \\mathbf{x_i}))}{\\delta(1 - S(\\theta^T \\mathbf{x_i}))}* \\frac{\\delta(1 - S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Използвайки логаритмичното правило от по-доре:\n",
    "\n",
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}y_i * \\frac {1}{ S(\\theta^T \\mathbf{x_i})}* \\frac{\\delta( S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T} + (1 - y_i) * \\frac{1}{(1 - S(\\theta^T \\mathbf{x_i}))}* \\frac{\\delta(1 - S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Използвайки Chain Rule:\n",
    "\n",
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}y_i * \\frac {1}{ S(\\theta^T \\mathbf{x_i})}* \\frac{\\delta( S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T x_i} * \\frac{\\delta \\theta^T x_i}{\\delta \\theta^T} + (1 - y_i) * \\frac{1}{(1 - S(\\theta^T \\mathbf{x_i}))}* \\frac{\\delta(1 - S(\\theta^T \\mathbf{x_i}))}{\\delta \\theta^T x_i} * \\frac{\\delta \\theta^T x_i}{\\delta \\theta^T}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Използвайки формулата за първата произвопдна на сигмоидната функция:\n",
    "\n",
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}y_i * \\frac {1}{ S(\\theta^T \\mathbf{x_i})}* S(\\theta^T \\mathbf{x_i}) * (1 - S(\\theta^T \\mathbf{x_i})) * x_i  + (1 - y_i) * (-1) * \\frac{1}{(1 - S(\\theta^T \\mathbf{x_i}))} * S(\\theta^T \\mathbf{x_i}) * (1 - S(\\theta^T \\mathbf{x_i})) * x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Съкращаваме:\n",
    "\n",
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}y_i * (1 - S(\\theta^T \\mathbf{x_i})) * x_i  - (1 - y_i) * S(\\theta^T \\mathbf{x_i}) * x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разкриваме скобите и съкращаваме:\n",
    "\n",
    "$$  \\frac{\\delta NLL}{\\delta \\theta^T} = \\space \\sum^n_{i = 0}(y_i - S(\\theta^T \\mathbf{x_i}))x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да се върнем към оптимизиращия метод:\n",
    "\n",
    "                                                For m in range(M):\n",
    "$$ \\theta = \\theta + \\alpha \\space \\sum^n_{i = 0}(y_i - S(\\theta^T \\mathbf{x_i}))x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Така след М на брой операции ще получим крайните стойности за $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следователно, когато тестваме данните:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искаме да изчислим вероятността за $y$ да бъде от клас 1 т.е. $y = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(y = 1\\mid \\mathbf{x})  = \\frac{1}{1 + e^{-(\\theta^T\\mathbf{x})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 1 Ако $ P(y = 1\\mid \\mathbf{x}) \\geq 0.5 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 0 Ако $ P(y = 1\\mid \\mathbf{x}) < 0.5 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прилагане на алгоритъма от нулата във вид на код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Classification\n",
    "## I am interested\n",
    "In the previous exercises, we looked at a **regression model**. Another type of widely used models is **classification**. Regression outputs a continuous value while classification outputs one of several pre-defined classes. In the most simple way, the classes are only two. For example, if we want to detect whether there's a cat on an image, we can have two classes: \"cat\" and \"non-cat\".\n",
    "\n",
    "Explore the problem of classification. Implement and document one algorithm. Apply it to some real-world data. You can use the following checklist:\n",
    "\n",
    "**Note:** If your paper is **about the algorithm**, consider **writing it from scratch**, not reusing it from a library.\n",
    "\n",
    "* What is supervised learning? What do supervised learning models do?\n",
    "* What is regression? What is classification?\n",
    "* What types of problems does classification solve directly? 143 > \n",
    "    * What types of problems can be reduced to classification?\n",
    "* What's the difference between two-class and multi-class classification?\n",
    "* Explore one algorithm for classification, e.g. logistic regression.\n",
    "    * State the problem clearly\n",
    "    * List all assumptions of the modelling function\n",
    "\n",
    "    * Describe the process: distances, error function, total loss, gradient descent, etc.; as needed\n",
    "    * Implement the algorithm from scratch\n",
    "* Select or generate a small dataset, suitable for classification. Run your algorithm as a sanity check\n",
    "* Debug and solve any problems\n",
    "* Waht is a confusion matrix?\n",
    "* What metrics are used to score a classifier?\n",
    "    * Accuracy, Precision, Recall, others\n",
    "    * ROC curve, interpretation\n",
    "* Select a real dataset\n",
    "    * Explore it to get acquainted with what information it contains\n",
    "    * Clean up the data if you need to do so\n",
    "    * Perform classification\n",
    "    * Score your classification model\n",
    "    * Use your classifier to predict\n",
    "        * Split the data into training and testing set\n",
    "        * Optionally, perform **cross-validation**\n",
    "    * Compare your implementation to another one, e.g. `scikit-learn`. They should give the same (or very similar) results\n",
    "    * Communicate the results on your dataset\n",
    "    * Optionally, publish your model on the Internet as a Web API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линкове, които използвах:\n",
    "\n",
    "[Logistic regression](https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html)\n",
    "\n",
    "[Natural logarithm](https://en.wikipedia.org/wiki/Natural_logarithm)\n",
    "\n",
    "[What is machine learning](https://www.geeksforgeeks.org/ml-machine-learning/)\n",
    "\n",
    "[What is machine learning](https://onlinestats.canr.udel.edu/machine-learning-vs-statistics/)\n",
    "\n",
    "[What is ML]([links](https://www.geeksforgeeks.org/ml-machine-learning/))\n",
    "\n",
    "[Introduction to statistical learning](https://people.unica.it/claudioconversano/files/2015/02/ISLR_print4.pdf)\n",
    "\n",
    "[Linear regression](https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html#multiple-linear-regression-predict)\n",
    "\n",
    "[Elements of statistical learning](https://github.com/tpn/pdfs/blob/master/The%20Elements%20of%20Statistical%20Learning%20-%20Data%20Mining,%20Inference%20and%20Prediction%20-%202nd%20Edition%20(ESLII_print4).pdf)\n",
    "\n",
    "[Logistic regression](https://towardsai.net/p/machine-learning/logistic-regression-with-mathematics)\n",
    "\n",
    "[Много добър индиец:)](https://www.youtube.com/watch?v=uFfsSgQgerw)\n",
    "\n",
    "[Cost function](https://www.bobbywlindsey.com/2019/11/06/understanding-maximum-likelihood-estimation/)\n",
    "\n",
    "[logs and odds explanation](https://www.youtube.com/watch?v=ARfXDSkQf1Y)\n",
    "\n",
    "[Very usefull video about logistic regression](https://www.youtube.com/watch?v=YMJtsYIp4kg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
